import cv2
import mediapipe as mp
import numpy as np
import time
import telebot
import tkinter as tk
from tkinter import ttk
from PIL import Image,ImageTk

# ë´‡ ì„¤ì •
token = '7366178157:AAG2MOVxAZXB2kB3l9r7uGCom5jP8DnR9dQ'  # ë´‡ í† í° (BotFatherì—ì„œ ë°›ì€ í† í°ìœ¼ë¡œ êµì²´)
bot = telebot.TeleBot(token=token)
user_id = 7287129421  # ì‚¬ìš©ì ID (ì•Œë¦¼ì„ ë°›ì„ ì‚¬ìš©ìì˜ Telegram ID)

# MediaPipe ì´ˆê¸°í™”
mp_drawing = mp.solutions.drawing_utils  # ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸° ìœ í‹¸ë¦¬í‹°
mp_pose = mp.solutions.pose  # ìì„¸ ì¶”ì • ëª¨ë¸
mp_face_detection = mp.solutions.face_detection  # ì–¼êµ´ ê°ì§€ ëª¨ë¸

# ì•Œë¦¼ ê¸°ì¤€ ê°’
ALERT_RIGHT_ANGLE_THRESHOLD = 70  # ì˜¤ë¥¸ìª½ ì–´ê¹¨-ê·€ ê°ë„ ê¸°ì¤€ (ì‚¬ìš©ì ì„¤ì •)
ALERT_LEFT_ANGLE_THRESHOLD = 110  # ì™¼ìª½ ì–´ê¹¨-ê·€ ê°ë„ ê¸°ì¤€ (ì‚¬ìš©ì ì„¤ì •)
FACE_SCALE_THRESHOLD = 1.5  # ì–¼êµ´ í¬ê¸° ì¦ê°€ ë¹„ìœ¨ ê¸°ì¤€
CHIN_TO_STERNUM_THRESHOLD = 0.7  # í„±-ëª…ì¹˜ ê±°ë¦¬ ê°ì†Œ ë¹„ìœ¨ ê¸°ì¤€
ALERT_INTERVAL = 5  # ì•Œë¦¼ ê°„ê²© (ì´ˆ)

# ë³€ìˆ˜ ì´ˆê¸°í™”
initial_face_size = None
initial_chin_to_sternum_distance = None
alert_time = None
is_measuring = False
measurement_type = None
countdown = 0
countdown_duration = 7

# ë¹„ë””ì˜¤ ìº¡ì²˜ ê°ì²´ ìƒì„± (ì›¹ìº  ì‚¬ìš©)
cap = cv2.VideoCapture(0)  # 0: ê¸°ë³¸ ì›¹ìº , ë‹¤ë¥¸ ì¹´ë©”ë¼ ì‚¬ìš© ì‹œ ë²ˆí˜¸ ë³€ê²½

# ê°ë„ ê³„ì‚° í•¨ìˆ˜
def calculate_angle(a, b):
    a = np.array(a)
    b = np.array(b)
    radians = np.arctan2(b[1] - a[1], b[0] - a[0])
    angle = np.abs(radians * 180.0 / np.pi)
    if angle > 180.0:
        angle = 360 - angle
    return angle

# Tkinter GUI ìƒì„±
root = tk.Tk()
root.title("ìì„¸ ì¸¡ì • í”„ë¡œê·¸ë¨")

# ì´ë¯¸ì§€ ë¡œë“œ ë° í‘œì‹œ
image_path = "./OPEN_CV_PROJECT/turtle_neck.png"  # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ (ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½)
image = Image.open(image_path)
image = image.resize((300, 200))  # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (ì„ íƒ ì‚¬í•­)
photo = ImageTk.PhotoImage(image)
image_label = ttk.Label(root, image=photo)
image_label.pack(pady=10)

# ë²„íŠ¼ í´ë¦­ ì´ë²¤íŠ¸ ì²˜ë¦¬ í•¨ìˆ˜
def start_measurement(selected_type):
    global measurement_type, countdown, is_measuring
    measurement_type = selected_type
    countdown = 7
    is_measuring = False
    root.destroy() 

def end_program():
    # ì›¹ìº  ë° OpenCV ì°½ í•´ì œ
    cap.release()
    cv2.destroyAllWindows()
    root.destroy()  # GUI ì°½ ë‹«ê¸°


# ë²„íŠ¼ ìƒì„±
ttk.Button(root, text="í„±-ëª…ì¹˜ ê±°ë¦¬ ì¸¡ì •", command=lambda: start_measurement('chin_to_sternum')).pack(pady=5)
ttk.Button(root, text="ì–¼êµ´ í¬ê¸° ë³€í™” ì¸¡ì •", command=lambda: start_measurement('face_size')).pack(pady=5)
ttk.Button(root, text="ë‹«ê¸°", command=lambda: end_program()).pack(pady=5)

description = ttk.Label(root, text="ì¸¡ì • ë°©ì‹ì„ íƒí•œ ë’¤ 7ì´ˆ ë’¤ì— ì¸¡ì •ì´ ì‹œì‘ë©ë‹ˆë‹¤.\në…¸íŠ¸ë¶ìœ„ì¹˜ì™€, ìµœëŒ€í•œ ë°”ë¥¸ ìì„¸ë¥¼ ì´ˆê¸°ì— ì¡ì•„ì£¼ì„¸ìš”!")
description.pack()

# GUI ì‹¤í–‰
root.mainloop()

# MediaPipe Pose ë° Face Detection ê°ì²´ ìƒì„±
with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose, \
     mp_face_detection.FaceDetection(min_detection_confidence=0.5) as face_detection:

    while cap.isOpened():
        success, image = cap.read()
        if not success:
            print("Ignoring empty camera frame.")
            continue

        # BGR ì´ë¯¸ì§€ë¥¼ RGBë¡œ ë³€í™˜
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image.flags.writeable = False

        # ì–¼êµ´ ê°ì§€
        face_results = face_detection.process(image)

        # ìì„¸ ì¶”ì •
        results = pose.process(image)

        # RGB ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ BGRë¡œ ë³€í™˜
        image.flags.writeable = True
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        image_height, image_width, _ = image.shape

        try:
            # ì¹´ìš´íŠ¸ë‹¤ìš´ ë° ì´ˆê¸°ê°’ ì„¤ì •
            if countdown > 0:
                cv2.putText(image, str(countdown), (image_width // 2, image_height // 2),
                            cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 3)
                time.sleep(1)
                countdown -= 1

                if countdown == 0:
                    is_measuring = True
                    if measurement_type == 'face_size':
                        if face_results.detections:
                            for detection in face_results.detections:
                                bbox = detection.location_data.relative_bounding_box
                                face_width = int(bbox.width * image_width)
                                face_height = int(bbox.height * image_height)
                                initial_face_size = (face_width + face_height) / 2
                    elif measurement_type == 'chin_to_sternum':
                        landmarks = results.pose_landmarks.landmark
                        nose = landmarks[mp_pose.PoseLandmark.NOSE]
                        sternum = ((landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x + landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x) / 2,
                                    (landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y + landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y) / 2)
                        initial_chin_to_sternum_distance = np.linalg.norm(np.array([nose.x, nose.y]) - np.array(sternum))
                    print("ì´ˆê¸°ê°’ ì„¤ì • ì™„ë£Œ!")

            # ì¸¡ì • ë° ì•Œë¦¼ (ì¸¡ì • ì¤‘ì¼ ë•Œë§Œ ì‹¤í–‰)
            if is_measuring:
                if measurement_type == 'face_size':
                    # ì–¼êµ´ í¬ê¸° ì¸¡ì • ë° ì‹œê°í™”
                    if face_results.detections:
                        for detection in face_results.detections:
                            bbox = detection.location_data.relative_bounding_box
                            x, y, w, h = int(bbox.xmin * image_width), int(bbox.ymin * image_height), \
                                         int(bbox.width * image_width), int(bbox.height * image_height)
                            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)  # ì–¼êµ´ ì˜ì—­ í‘œì‹œ

                            face_size = (w + h) / 2
                            face_scale = face_size / initial_face_size
                            cv2.putText(image, f"Face Scale: {face_scale:.2f}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

                            if face_scale > FACE_SCALE_THRESHOLD:
                                current_time = time.time()
                                if alert_time is None or current_time - alert_time >= ALERT_INTERVAL:
                                    print("Alert: ì–¼êµ´ì´ ê°€ê¹Œì›Œì¡ŒìŠµë‹ˆë‹¤. ìì„¸ë¥¼ ë’¤ë¡œ ì¡°ì •í•˜ì„¸ìš”.")
                                    bot.send_message(user_id, "ğŸ¢")
                                    alert_time = current_time
                elif measurement_type == 'chin_to_sternum':
                    # í„±-ëª…ì¹˜ ê±°ë¦¬ ì¸¡ì • ë° ì‹œê°í™”
                    landmarks = results.pose_landmarks.landmark
                    nose = landmarks[mp_pose.PoseLandmark.NOSE]
                    sternum = ((landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x + landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x) / 2,
                               (landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y + landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y) / 2)
                    chin_to_sternum_distance = np.linalg.norm(np.array([nose.x, nose.y]) - np.array(sternum))

                    nose_px = (int(nose.x * image_width), int(nose.y * image_height))
                    sternum_px = (int(sternum[0] * image_width), int(sternum[1] * image_height))
                    cv2.line(image, nose_px, sternum_px, (0, 255, 0), 2)  # í„±-ëª…ì¹˜ ì„  í‘œì‹œ

                    chin_to_sternum_ratio = chin_to_sternum_distance / initial_chin_to_sternum_distance
                    cv2.putText(image, f"Chin to Sternum Ratio: {chin_to_sternum_ratio:.2f}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

                    if chin_to_sternum_ratio < CHIN_TO_STERNUM_THRESHOLD:
                        current_time = time.time()
                        if alert_time is None or current_time - alert_time >= ALERT_INTERVAL:
                            print("Alert: ê³ ê°œë¥¼ ìˆ™ì´ê³  ìˆìŠµë‹ˆë‹¤. ìì„¸ë¥¼ ë°”ë¥´ê²Œ í•˜ì„¸ìš”.")
                            bot.send_message(user_id, "ğŸ¢")
                            alert_time = current_time

        except Exception as e:
            print(f"Error processing landmarks: {e}")

        # ê²°ê³¼ ì´ë¯¸ì§€ í‘œì‹œ
        cv2.imshow('MediaPipe Pose', image)  # ì°½ ì´ë¦„: 'MediaPipe Pose'

        if cv2.waitKey(5) & 0xFF == 27:  # ESC í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œ (5ms ëŒ€ê¸°)
            break

# ì›¹ìº  ë° OpenCV ì°½ í•´ì œ
cap.release()
cv2.destroyAllWindows()
